{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYs6LMEbNqoQ"
   },
   "source": [
    "# RL homework 4\n",
    "\n",
    "------------------------------------\n",
    "\n",
    "## How to Submit\n",
    "\n",
    "When you have completed the exercises and everything has finsihed running, click on 'File' in the menu-bar and then 'Download .ipynb'. This file must be submitted to Moodle named as **studentnumber_RL_hw4.ipynb** before the deadline above.\n",
    "\n",
    "Also send a **sharable link** to the notebook at the following email: ucl.coursework.submit@gmail.com. You can also make it sharable via link to everyone, up to you.\n",
    "\n",
    "Please compile all results and all answers to the understanding questions into a PDF. Name convention: **studentnumber_RL_hw4.pdf**. Do not include any of the code (we will use the notebook for that). \n",
    "\n",
    "**Page limit: 10 pg **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9v_SYckYfv5G"
   },
   "source": [
    "## Context\n",
    "\n",
    "In this assignment, we will take a first look at learning decisions from data.  For this, we will use the multi-armed bandit framework.\n",
    "\n",
    "## Background reading\n",
    "\n",
    "* Sutton and Barto (2018), Chapters 6-7 + 9-11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ztQEQvnKh2t6"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qB0tQ4aiAaIu"
   },
   "source": [
    "### Import Useful Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YzYtxi8Wh5SJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NDhSYfSDcCC"
   },
   "source": [
    "### Set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ps5OnkPmDbMX"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOu9RZY3AkF1"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6EttQGJ1n5Zn"
   },
   "outputs": [],
   "source": [
    "def run_experiment(env, agent, number_of_steps):\n",
    "    mean_reward = 0.\n",
    "    try:\n",
    "      action = agent.initial_action()\n",
    "    except AttributeError:\n",
    "      action = 0\n",
    "    for i in range(number_of_steps):\n",
    "      reward, discount, next_state = grid.step(action)\n",
    "      action = agent.step(reward, discount, next_state)\n",
    "      mean_reward += (reward - mean_reward)/(i + 1.)\n",
    "\n",
    "    return mean_reward\n",
    "\n",
    "map_from_action_to_subplot = lambda a: (2, 6, 8, 4)[a]\n",
    "map_from_action_to_name = lambda a: (\"up\", \"right\", \"down\", \"left\")[a]\n",
    "\n",
    "def plot_values(values, colormap='pink', vmin=None, vmax=None):\n",
    "  plt.imshow(values, interpolation=\"nearest\", cmap=colormap, vmin=vmin, vmax=vmax)\n",
    "  plt.yticks([])\n",
    "  plt.xticks([])\n",
    "  plt.colorbar(ticks=[vmin, vmax])\n",
    "#   plt.colorbar()\n",
    "\n",
    "def plot_action_values(action_values, vmin=None, vmax=None):\n",
    "  q = action_values\n",
    "  fig = plt.figure(figsize=(8, 8))\n",
    "  fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "  for a in [0, 1, 2, 3]:\n",
    "    plt.subplot(3, 3, map_from_action_to_subplot(a))\n",
    "    plot_values(q[..., a], vmin=vmin, vmax=vmax)\n",
    "    action_name = map_from_action_to_name(a)\n",
    "    plt.title(r\"$q(s, \\mathrm{\" + action_name + r\"})$\")\n",
    "    \n",
    "  plt.subplot(3, 3, 5)\n",
    "  v = 0.9 * np.max(q, axis=-1) + 0.1 * np.mean(q, axis=-1)\n",
    "  plot_values(v, colormap='summer', vmin=vmin, vmax=vmax)\n",
    "  plt.title(\"$v(s)$\")\n",
    "\n",
    "\n",
    "def plot_rewards(xs, rewards, color):\n",
    "  mean = np.mean(rewards, axis=0)\n",
    "  p90 = np.percentile(rewards, 90, axis=0)\n",
    "  p10 = np.percentile(rewards, 10, axis=0)\n",
    "  plt.plot(xs, mean, color=color, alpha=0.6)\n",
    "  plt.fill_between(xs, p90, p10, color=color, alpha=0.3)\n",
    "  \n",
    "\n",
    "def parameter_study(parameter_values, parameter_name,\n",
    "  agent_constructor, env_constructor, color, repetitions=10, number_of_steps=int(1e4)):\n",
    "  mean_rewards = np.zeros((repetitions, len(parameter_values)))\n",
    "  greedy_rewards = np.zeros((repetitions, len(parameter_values)))\n",
    "  for rep in range(repetitions):\n",
    "    for i, p in enumerate(parameter_values):\n",
    "      env = env_constructor()\n",
    "      agent = agent_constructor()\n",
    "      if 'eps' in parameter_name:\n",
    "        agent.set_epsilon(p)\n",
    "      elif 'alpha' in parameter_name:\n",
    "        agent._step_size = p\n",
    "      else:\n",
    "        raise NameError(\"Unknown parameter_name: {}\".format(parameter_name))\n",
    "      mean_rewards[rep, i] = run_experiment(grid, agent, number_of_steps)\n",
    "      agent.set_epsilon(0.)\n",
    "      agent._step_size = 0.\n",
    "      greedy_rewards[rep, i] = run_experiment(grid, agent, number_of_steps//10)\n",
    "      del env\n",
    "      del agent\n",
    "\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plot_rewards(parameter_values, mean_rewards, color)\n",
    "  plt.yticks=([0, 1], [0, 1])\n",
    "  # plt.ylim((0, 1.5))\n",
    "  plt.ylabel(\"Average reward over first {} steps\".format(number_of_steps), size=12)\n",
    "  plt.xlabel(parameter_name, size=12)\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plot_rewards(parameter_values, greedy_rewards, color)\n",
    "  plt.yticks=([0, 1], [0, 1])\n",
    "  # plt.ylim((0, 1.5))\n",
    "  plt.ylabel(\"Final rewards, with greedy policy\".format(number_of_steps), size=12)\n",
    "  plt.xlabel(parameter_name, size=12)\n",
    "  \n",
    "def epsilon_greedy(q_values, epsilon):\n",
    "  if epsilon < np.random.random():\n",
    "    return np.argmax(q_values)\n",
    "  else:\n",
    "    return np.random.randint(np.array(q_values).shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTJ3WYL8Y0GQ"
   },
   "source": [
    "### A small MRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iPnQLBHsYzdq"
   },
   "outputs": [],
   "source": [
    "class SmallMRP(object):\n",
    "\n",
    "  def __init__(self, p=0.1):\n",
    "    self._state = 0\n",
    "    self._p = p\n",
    "\n",
    "  def get_state(self):\n",
    "    return self._state\n",
    "\n",
    "  def step(self):\n",
    "    reward = 0\n",
    "    discount = 1\n",
    "    if self._state == 0:\n",
    "      self._state = 1\n",
    "    else:\n",
    "      if np.random.random() < self._p:\n",
    "        self._state = 0\n",
    "        discount = 0\n",
    "      else:\n",
    "        self._state = 1\n",
    "\n",
    "    return reward, discount, self.get_obs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HdojBKQ2CK9e"
   },
   "source": [
    "## Assignment 1 [50pts in total]\n",
    "\n",
    "We are going to analyze the simple Markov reward process (MRP - a MRP is an MDP without actions or, equivalently, with a single action in each state) defined in the code cell above.  It consists of two states.  The reward is zero everywhere.  When we are in state $s_0$, we always transition to $s_1$.  If we are in state $s_1$, there is a probability $p$ (which is set to 0.1 by default in the code above) of terminating, after which the next episode starts in $s_0$ again.  With a probability of $1 - p$, we transition from $s_1$ back to itself again.  The discount is $\\gamma = 1$ on non-terminal steps.\n",
    "\n",
    "#### [1pt] Question 1.1\n",
    "What is the optimal value in each state?\n",
    "\n",
    "As there are no reward, the optimla value is 0 for each of the two states.\n",
    "\n",
    "#### [1pt] Question 1.2\n",
    "Instead of a tabular representation, consider a single feature $\\phi$, which takes the values $\\phi(s_0) = 1$ and $\\phi(s_1) = 4$.  Now consider using linear function approximation, where we learn a value $\\theta$ such that $v_{\\theta}(s) = \\theta \\times \\phi(s) \\approx v(s)$, where $v(s)$ is the true value of state $s$.  What is the optimal value of $\\theta$?\n",
    "\n",
    "The optimal value of $\\theta$ is 0 since there is no reward in the MRP. \n",
    "\n",
    "#### [8pts] Question 1.3\n",
    "Suppose $\\theta_0 = 1$, and suppose we update this parameter with TD(0) with a step size of $\\alpha = 0.1$.  What is the expected value of $\\mathbb{E}[ \\theta_T ]$ if we step through the MDP until it terminates after the first episode, as a function of $p$?  (Note that $T$ is random.)\n",
    "\n",
    "The TD(0) update for the parameter using gradient descent:\n",
    "\n",
    "$\\theta_{t+1} = \\theta_{t}+\\alpha(R+\\gamma v_{\\theta_{t}}(s')-v_{\\theta_{t}}(s))\\nabla v_{\\theta_{t}}(s)$ with $R=0$\n",
    "\n",
    "$\\theta_{t+1} = \\theta_{t}+\\alpha(\\gamma\\theta_{t}\\phi(s') -\\theta_{t}\\phi(s) )\\phi(s) = \\theta_{t}(1+\\alpha(\\gamma\\phi(s')-\\phi(s))\\phi(s))$\n",
    "\n",
    "For $s_{0}\\rightarrow s_{1}$ and $s_{1}\\rightarrow s_{1}$: $\\gamma = 1$; for $s_{1}\\rightarrow s_{0}$, $\\gamma=0$ as there is no need to boostrap for the terminate state. \n",
    "\n",
    "At the start of the episode, we have transition $s_{0}\\rightarrow s_{1}$ with $prob=1$ and at the end of the episode with transition $s_{1}\\rightarrow s_{0}$ with $prob=p$. The other transitions are T-2 numbers of $s_{1}\\rightarrow s_{1}$ with $prob=1-p$\n",
    "\n",
    "Therefore with $\\theta_{0}=1$, $\\alpha = 0.1$, $\\phi(s_{0})=1$ and $\\phi(s_{1})=4$, the expectation could be written as:\n",
    "\n",
    "$\\mathbb{E}[ \\theta_T ] = \\sum_{T=2}^{\\infty}\\theta_{0}(1+\\alpha(\\phi(s_{1})-\\phi(s_{0}))\\phi(s_{0}))(1+\\alpha(\\phi(s_{1})-\\phi(s_{1}))\\phi(s_{1}))^{T-2}(1+\\alpha(-\\phi(s_{1}))\\phi(s_{1}))(1-p)^{T-2}p$\n",
    "\n",
    "\n",
    "$=1.3\\times (-0.6)p\\sum_{T=2}^{\\infty}(1-p)^{T-2}$\n",
    "\n",
    "$=-0.78p\\times \\frac{1}{1-(1-p)} = -0.78p^{0} = -0.78$\n",
    "\n",
    "\n",
    "\n",
    "#### [5pts] Question 1.3\n",
    "If $p=0.1$, how many episodes does it take, starting from $\\theta_0 = 1$, until $| v(s) - \\mathbb{E}[v_{\\theta}(s)] | < 0.5$ for all $s$, where the expectation is over the expected updates to $\\theta$?\n",
    "\n",
    "For $p=0.1$, suppose we need $n$ episodes\n",
    "\n",
    "Since $\\mathbb{E}[v_{\\theta}(s)] = \\mathbb{E}[\\phi(s)\\theta_{T}] = \\phi(s)\\mathbb{E}[\\theta_{T}]$: \n",
    "\n",
    "For $s_{0}$ we have $| v(s_{0}) - \\mathbb{E}[v_{\\theta}(s_{0})] | = | \\phi(s_{0})\\mathbb{E}[\\theta_{T}] | = | \\mathbb{E}[\\theta_{T}] | < 0.5$\n",
    "\n",
    "For $s_{1}$ we have $| v(s_{1}) - \\mathbb{E}[v_{\\theta}(s_{1})] | = | \\phi(s_{1})\\mathbb{E}[\\theta_{T}] | = 4| \\mathbb{E}[\\theta_{T}] | < 0.5 \\rightarrow | \\mathbb{E}[\\theta_{T}] | < 0.125$\n",
    "\n",
    "In this case of n episodes\n",
    "$\\mathbb{E}[ \\theta_T ] = \\sum_{T=2n}^{\\infty}\\theta_{0}(1+\\alpha(\\phi(s_{1})-\\phi(s_{0}))\\phi(s_{0}))^{n}(1+\\alpha(\\phi(s_{1})-\\phi(s_{1}))\\phi(s_{1}))^{T-2n}(1+\\alpha(-\\phi(s_{1}))\\phi(s_{1}))^{n}(1-p)^{T-2}p^{n}$\n",
    "\n",
    "$=1.3^{n}\\times(-0.6)^{n}\\times(0.1)^{n}\\times \\sum_{T=2n}^{\\infty}(1-0.1)^{T-2n}$\n",
    "\n",
    "$=(-0.078)^{n}\\times 10 < 0.125$ \n",
    "\n",
    "Hence it takes $n=2$ episodes. \n",
    "\n",
    "#### Synchronous updates\n",
    "Consider the following algorithm: we use TD to update the parameters, but instead of using the online data, we assume we can actively sample a transition from both states.  We then update $\\theta$ using both samples:\n",
    "$$\n",
    "\\theta_{n+1} = \\theta_n + \\alpha \\delta_0 \\phi(s_0) + \\alpha \\delta_1 \\phi(s_1) \\,,\n",
    "$$\n",
    "where $\\delta_i$ is a sampled one-step TD error when transitioning from state $s_i$.\n",
    "\n",
    "#### [10pts] Question 1.4\n",
    "\n",
    "What is the value of $\\mathbb{E}[\\theta_n]$, as a function of $n$ and $p$?\n",
    "\n",
    "We have $\\delta_0 = \\theta_{n}\\phi(s_{1})-\\theta_{n}\\phi(s_{0}) = \\theta_{n}(\\phi(s_{1})-\\phi(s_{0}))$\n",
    "\n",
    "For transition $s_{1}$ to $s_{0}$ (with $prob = p$): \n",
    "\n",
    "$\\delta_1  = -\\theta_{n}\\phi(s_{1}) $\n",
    "\n",
    "$\\theta_{n+1}=\\theta_{n}+\\alpha\\theta_{n}(\\phi(s_{1})-\\phi(s_{0}))\\phi(s_{0})+\\alpha\\theta_{n}(-\\phi(s_{1})\\phi(s_{1}))$\n",
    "\n",
    "$ = \\theta_{n}(1+\\alpha(\\phi(s_{1})\\phi(s_{0})-\\phi(s_{0})\\phi(s_{0})-\\phi(s_{1})\\phi(s_{1}))) = \\theta_{n}\\Delta_{10}$\n",
    "\n",
    "For transition $s_{1}$ to $s_{1}$ (with $prob = 1-p$): \n",
    "\n",
    "$\\delta_1  = 0 $\n",
    "\n",
    "$\\theta_{n+1}=\\theta_{n}+\\alpha\\theta_{n}(\\phi(s_{1})-\\phi(s_{0}))\\phi(s_{0})$\n",
    "\n",
    "$=\\theta_{n}(1+\\alpha(\\phi(s_{1})\\phi(s_{0})-\\phi(s_{0})\\phi(s_{0})))=\\theta_{n}\\Delta_{11}$\n",
    "\n",
    "Therefore the expectation will be:\n",
    "\n",
    "$\\mathbb{E}[\\theta_{T}] = \\sum_{k=1}^{n}\\theta_{0}(\\Delta_{10})^{k}p^{k}(\\Delta_{11})^{n-k}(1-p)^{n-k}$\n",
    "\n",
    "Therefore with $\\theta_{0}=1$, $\\alpha = 0.1$, $\\phi(s_{0})=1$ and $\\phi(s_{1})=4$, the expectation could be written as:\n",
    "\n",
    "$\\mathbb{E}[\\theta_{T}] = \\sum_{k=1}^{n}(-0.3)^{k}p^{k}(1.3)^{n-k}(1-p)^{n-k}$\n",
    "\n",
    "$ = (1.3(1-p))^{n}\\sum_{k=1}^{n}(\\frac{-0.3p}{1.3(1-p)})^{k} = (1.3(1-p))^{n}\\frac{w(1-w^{n-1})}{1-w}$, where $w = \\frac{-0.3p}{1.3(1-p)}$\n",
    "\n",
    "$ = (-0.3p(1.3(1-p))^{n-1}-(-0.3p)^{n})/(1+\\frac{0.3p}{1.3(1-p)})$\n",
    "\n",
    "#### [5pts] Question 1.5\n",
    "\n",
    "For which values of $p$ does not $\\theta$ converge to the optimal solution?\n",
    "\n",
    "On basis of the expression from last question: \n",
    "\n",
    "if $1.3(1-p)>1 \\rightarrow p<\\frac{3}{13}$ then $(1.3(1-p))^{n-1}\\rightarrow \\infty$ as $n \\rightarrow \\infty$\n",
    "\n",
    "And thus $\\theta$ will not converge to the optimal solution\n",
    "\n",
    "#### [10pts] Question 1.5\n",
    "Why doesn't it?  TD is known to converge, with linear function approximation, under certain assumptions.  Explain for this concrete case why the algorithm does not converge, and explain which general assumption is violated that would otherwise ensure convergence of linear TD (in at most 200 words).\n",
    "\n",
    "Refer to Q1.4, we have got the update funciton for $\\theta$:\n",
    "\n",
    "let $\\phi_0 = \\phi(s_{0})$, $\\phi_1 = \\phi(s_{1})$\n",
    "\n",
    "With $prob=p$:\n",
    "\n",
    "$\\theta_{n+1} = \\theta_{n}+\\alpha\\theta_{n}(\\phi_1\\phi_0-\\phi_0\\phi_0-\\phi_1\\phi_1) = (1-\\alpha A)\\theta_{n}$\n",
    "\n",
    "where $A = \\phi_0\\phi_0+\\phi_1\\phi_1-\\phi_1\\phi_0$\n",
    "\n",
    "with $prob=1-p$:\n",
    "\n",
    "$\\theta_{n+1} = \\theta_{n}+\\alpha\\theta_{n}(\\phi_1\\phi_0-\\phi_0\\phi_0) = (1-\\alpha A)\\theta_{n}$\n",
    "\n",
    "Where $A = \\phi_0\\phi_0-\\phi_1\\phi_0$\n",
    "\n",
    "The expectation of the update will be: \n",
    "\n",
    "$\\mathbb{E}[\\theta_{n+1} | \\theta_{n}] = (1-\\alpha\\mathbb{E}[A])\\theta_{n}$ \n",
    "\n",
    "And $\\mathbb{E}[A] = p(\\phi_0\\phi_0+\\phi_1\\phi_1-\\phi_1\\phi_0)+(1-p)(\\phi_0\\phi_0-\\phi_1\\phi_0) = \\phi_0\\phi_0+p\\phi_1\\phi_1-\\phi_1\\phi_0$\n",
    "\n",
    "which could be written as $\\mathbb{E}[A] = \\mu^{T}P \\mu$ \n",
    "\n",
    "where $\\mu = \\begin{pmatrix}\\phi_0\\\\\\phi_1\\end{pmatrix}$ and $P = \\begin{pmatrix} 1 & b \\\\c & p \\end{pmatrix}$ with $b+c=-1$ \n",
    "\n",
    "$P$ might not be positive definite with specific value of $p$ and hence $\\mathbb{E}[A]$ might not be positive definite.\n",
    "\n",
    "(In our case of $\\phi_0=1$ and $\\phi_1=4$, $\\mathbb{E}[A] = 16p-3$. It cannot be guaranteed to be larger than 0. \n",
    "\n",
    "If $\\mathbb{E}[A]<0$, we have $(1-\\alpha\\mathbb{E}[A])>0$ for all $\\alpha$. Therefore the update of $\\theta_t$ will be amplified which will lead to divergence. )\n",
    "\n",
    "In such a scenario, matrix/value $\\mathbb{E}[A]$ should be positive (definite) in the general case. The assumption that $\\gamma<1$ is also violated which is used to ensure the property of positive defenite. \n",
    "\n",
    "Furthmore, this sychronous update algorithm combine (linear) function approximation, boostrap(TD(0)) and off policy all together, which might cause Deadly Triad issue and lead to problem of instability and divergence. \n",
    "\n",
    "#### [10pts] Question 1.5\n",
    "Describe a way to change the algorithm to obtain convergence of $\\theta$, for any $p$, without changing the sampling or the value function (which should remain as $v_{\\theta}(s) = \\theta \\times \\phi(s)$).  Note that the sampling is not sequential, so for instance you cannot add memory of previous states.  (At most 200 words.)\n",
    "\n",
    "We could change algorithm to use online update instead of offline update which will not lead to deadly triad.\n",
    "\n",
    "Furthermore, We could change the synchronous update algorithm to: do not update the parameter ($\\theta$) if sample to transit from state 1 to itself at state 1 (with $prob=1-p$). Follow this algorithm, $\\mathbb{E}[A]$ in the expectation of each update $\\mathbb{E}[\\theta_{n+1} | \\theta_{n}]$will become: \n",
    "\n",
    "$\\mathbb{E}[A] = p(\\phi_0\\phi_0+\\phi_1\\phi_1-\\phi_1\\phi_0) = 13p > 0$ for all $p$ (with $\\phi_0=1$ and $\\phi_1=4$)\n",
    "\n",
    "which could be written as $\\mathbb{E}[A] = \\mu^{T}\\begin{pmatrix} 1 & b \\\\c & 1 \\end{pmatrix} \\mu$ where $\\mu = \\begin{pmatrix}\\phi_0\\\\\\phi_1\\end{pmatrix}$\n",
    "\n",
    "$P = \\begin{pmatrix} 1 & b \\\\c & 1 \\end{pmatrix}$ with $b+c=-1$\n",
    "\n",
    "Hence $\\mathbb{E}[A]$ must be positive (definite) since P is positive definite and the algorithm is guanranteed to converge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4v8_c7XqsEo"
   },
   "source": [
    "## Assignment 2 [50pts in total + 10 BONUS pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ALrRR76eAd6u"
   },
   "source": [
    "### A grid world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YP97bVN3NuG8"
   },
   "outputs": [],
   "source": [
    "class Grid(object):\n",
    "\n",
    "  def __init__(self, tabular=True, vision_size=1, noisy=False):\n",
    "    # -1: wall\n",
    "    # 0: empty, episode continues\n",
    "    # other: number indicates reward, episode will terminate\n",
    "    self._layout = np.array([\n",
    "      [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "      [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
    "      [-1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1],\n",
    "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
    "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
    "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
    "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
    "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
    "      [-1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1, -1,  0, -1, -1, -1],\n",
    "      [-1, -1, -1, -5, -1, -1, -1, -1, -6, -1, -1, -1, -1, 10, -1, -1, -1],\n",
    "      [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "      [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "    ])\n",
    "    self._start_state = (3, 2)\n",
    "    self._state = self._start_state\n",
    "    self._number_of_states = np.prod(np.shape(self._layout))\n",
    "    self._noisy = noisy\n",
    "    self._tabular = tabular\n",
    "    self._vision_size = vision_size\n",
    "\n",
    "  @property\n",
    "  def number_of_states(self):\n",
    "      return self._number_of_states\n",
    "    \n",
    "  def plot_grid(self):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(self._layout != -1, interpolation=\"nearest\", cmap='pink')\n",
    "    ax = plt.gca()\n",
    "    ax.grid(0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"The grid\")\n",
    "    plt.text(3, 2, r\"$\\mathbf{S}$\", ha='center', va='center')\n",
    "    goal_y, goal_x = np.where(self._layout==10)\n",
    "    plt.text(goal_x, goal_y, r\"$\\mathbf{G}$\", ha='center', va='center')\n",
    "    goal_y, goal_x = np.where(self._layout==-5)\n",
    "    plt.text(goal_x, goal_y, r\"$\\mathbf{D}$\", ha='center', va='center')\n",
    "    goal_y, goal_x = np.where(self._layout==-6)\n",
    "    plt.text(goal_x, goal_y, r\"$\\mathbf{D}$\", ha='center', va='center')\n",
    "    h, w = self._layout.shape\n",
    "    for y in range(h-1):\n",
    "      plt.plot([-0.5, w-0.5], [y+0.5, y+0.5], '-k', lw=2)\n",
    "    for x in range(w-1):\n",
    "      plt.plot([x+0.5, x+0.5], [-0.5, h-0.5], '-k', lw=2)\n",
    "\n",
    "  def get_obs(self):\n",
    "    y, x = self._state\n",
    "    return self.get_obs_at(x, y)\n",
    "\n",
    "  def get_obs_at(self, x, y):\n",
    "    if self._tabular:\n",
    "      return y*self._layout.shape[1] + x\n",
    "    else:\n",
    "      v = self._vision_size\n",
    "      location = np.clip(-self._layout[y-v:y+v+1,x-v:x+v+1], 0, 1)\n",
    "      return location\n",
    "\n",
    "  def step(self, action):\n",
    "    y, x = self._state\n",
    "    \n",
    "    if action == 0:  # up\n",
    "      new_state = (y - 1, x)\n",
    "    elif action == 1:  # right\n",
    "      new_state = (y, x + 1)\n",
    "    elif action == 2:  # down\n",
    "      new_state = (y + 1, x)\n",
    "    elif action == 3:  # left\n",
    "      new_state = (y, x - 1)\n",
    "    else:\n",
    "      raise ValueError(\"Invalid action: {} is not 0, 1, 2, or 3.\".format(action))\n",
    "\n",
    "    new_y, new_x = new_state\n",
    "    discount = 0.98\n",
    "    if self._layout[new_y, new_x] == -1:  # wall\n",
    "      reward = -1\n",
    "      new_state = (y, x)\n",
    "    elif self._layout[new_y, new_x] != 0: # a goal\n",
    "      reward = self._layout[new_y, new_x]\n",
    "      discount = 0.\n",
    "      new_state = self._start_state\n",
    "    else:\n",
    "      reward = (new_y + new_x) / np.sum(self._layout.shape)\n",
    "    if self._noisy:\n",
    "      width = self._layout.shape[1]\n",
    "      reward += 2*np.random.normal(0, width - new_x + new_y)\n",
    "    \n",
    "    self._state = new_state\n",
    "\n",
    "    return reward, discount, self.get_obs()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaGeLcsvixmt"
   },
   "source": [
    "### The grid\n",
    "\n",
    "The cell below shows the `Grid` environment that we will use. Here `S` indicates the start state and `G` indicates the goal.  The agent has four possible actions: up, right, down, and left.  Rewards are: `-1` for bumping into a wall, `+10` for reaching the goal, and `(x + y)/(height + width)` otherwise, which encourages the agent to go right and down.  The episode ends when the agent reaches the goal.  At the end of the left-most two corridors, there are distractor 'goals' (marked `D`) that give a reward of $-5$ and $-6$, and then also terminate the episode.  The discount, on continuing steps, is $\\gamma = 0.98$.  Feel free to reference the implemetation of the `Grid` above, under the header \"a grid world\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 723,
     "status": "ok",
     "timestamp": 1524142032939,
     "user": {
      "displayName": "Yucheng Ji",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102198880449804016310"
     },
     "user_tz": -60
    },
    "id": "SlFuWFzIi5uB",
    "outputId": "8a95515a-dfe2-4d34-c5fb-361fbefc9762"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nogWMIVrAGKIFjCFawBiiBYz5GxX6tQL0cjeKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fedfac2e750>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = Grid()\n",
    "grid.plot_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKfA7ifHvO-M"
   },
   "source": [
    "\n",
    "## Implement agents\n",
    "**[10 pts]** In the next code cell, implement an agent that uses **tabular Sarsa** to learn action values.  The agent should act according to an $\\epsilon$-greedy policy with respect to its action values.\n",
    "\n",
    "The agent will be initialized with:\n",
    "```\n",
    "agent = Sarsa(number_of_states=grid._layout.size,\n",
    "              number_of_actions=4,\n",
    "              grid.get_obs())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "u_hLSL8anhsv"
   },
   "outputs": [],
   "source": [
    "class Sarsa(object):\n",
    "\n",
    "  def __init__(self, number_of_states, number_of_actions, initial_state, step_size=0.1):\n",
    "    self.state = initial_state\n",
    "    self.action = 0\n",
    "    self.q = np.zeros([number_of_states,number_of_actions])\n",
    "    self.alpha = step_size\n",
    "    \n",
    "  @property\n",
    "  def q_values(self):\n",
    "    # This function should return the action values for all states and actions\n",
    "    # in a numpy arrar of shape (number_of_states, number_of_actions)\n",
    "    return self.q\n",
    "\n",
    "  def step(self, r, g, s):\n",
    "    # This function should return an action\n",
    "    next_a = epsilon_greedy(self.q[s,:], epsilon=0.1)\n",
    "    self.q[self.state,self.action] += self.alpha*(r+g*self.q[s,next_a]-self.q[self.state,self.action])\n",
    "    self.state = s\n",
    "    self.action = next_a\n",
    "    return self.action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oMr_z0RZsHNj"
   },
   "source": [
    "**[20 pts]** Implement an agent that uses **neural Sarsa** to learn action values.  The agent should expect a nxn input which it should flatten into a vector, and then pass through a multi-layer perceptron with a single hidden layer with 100 hidden nodes and ReLU activations.  Each weight layer should also have a bias.  Initialize all weights uniformly randomly in $[-0.05, 0.05]$.\n",
    "\n",
    "```\n",
    "NeuralSarsa(number_of_features=(2*vision_size + 1)**2,\n",
    "            number_of_hidden=100,\n",
    "            number_of_actions=4,\n",
    "            initial_state=grid.get_obs(),\n",
    "            step_size=0.01)\n",
    "```\n",
    "\n",
    "The number `vision_size` will be either 1 or 2 below.  The input vector will be of size $(2v + 1)^2$, which will correspond to a square local view of the grid, centered on the agent, and of size $(2v + 1) \\times (2v + 1)$ (so either 3x3 or 5x5).\n",
    "\n",
    "You are allowed, but not mandated, to use TensorFlow to implement this agent.  (The network is small enough that you can also use numpy, but then you have to implement your own backprop.)  Please document the code clearly, especially on non-trivial operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fppAqbUOn8cO"
   },
   "outputs": [],
   "source": [
    "class NeuralSarsa(object):\n",
    "\n",
    "  def __init__(self, number_of_features, number_of_hidden, number_of_actions, initial_state, step_size=0.01):\n",
    "    self.state = initial_state\n",
    "    self.action = 0\n",
    "    # initialize the weight and bias in the NN\n",
    "    self.W1 = np.random.uniform(-0.05,0.05,[number_of_features,number_of_hidden])\n",
    "    self.b1 = np.zeros(number_of_hidden)\n",
    "    self.W2 = np.random.uniform(-0.05,0.05,[number_of_hidden,number_of_actions])\n",
    "    self.b2 = np.zeros(number_of_actions)    \n",
    "    self.alpha = step_size\n",
    "    self.all_a = np.eye(number_of_actions)\n",
    "    \n",
    "  def forward(self,x):\n",
    "    h = x.dot(self.W1)+self.b1\n",
    "    relu = np.maximum(h,0)\n",
    "    z = relu.dot(self.W2)+self.b2\n",
    "    return h,relu,z\n",
    "  \n",
    "  def gradients(self,x,W,dL_dz):\n",
    "    dL_dW = np.dot(x.reshape(-1,1),dL_dz.reshape(1,-1))\n",
    "    dL_db = np.copy(dL_dz)\n",
    "    dL_dx = np.dot(W,dL_dz)\n",
    "    return dL_dW,dL_db,dL_dx\n",
    "  \n",
    "  def ReLU_gradients(self,dL_dz,x):\n",
    "    return dL_dz*(x>0)\n",
    "  \n",
    "  def q(self, obs):\n",
    "    # This function should give the vector of action values for observation obs\n",
    "    _,_,z = self.forward(obs.reshape(-1,))\n",
    "    return z\n",
    "  \n",
    "  def step(self, r, g, s):\n",
    "    # This function should return an action\n",
    "    Q_s = self.q(s)\n",
    "    next_a = epsilon_greedy(Q_s,epsilon=0.1)\n",
    "#     target[self.action] = r+g*(self.q(s)[next_a])\n",
    "    # Forward:\n",
    "    h,relu,z = self.forward(self.state.reshape(-1,))\n",
    "    # Target:\n",
    "    target = np.copy(z)\n",
    "    target[self.action] = r+g*(Q_s[next_a])\n",
    "    # Backward:\n",
    "    dL_dz = -(target-z)\n",
    "    dW2,db2,drelu = self.gradients(relu,self.W2,dL_dz)\n",
    "    dh = self.ReLU_gradients(drelu,h)\n",
    "    dW1,db1,_ = self.gradients(self.state.reshape(-1,),self.W1,dh)\n",
    "    # update:\n",
    "    self.W1 -= self.alpha * dW1\n",
    "    self.b1 -= self.alpha * db1\n",
    "    self.W2 -= self.alpha * dW2\n",
    "    self.b2 -= self.alpha * db2\n",
    "    \n",
    "    self.state = s\n",
    "    self.action = next_a\n",
    "    \n",
    "    return self.action\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jZsPzCmDxAh"
   },
   "source": [
    "# Analyse Results - (using Python 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQkk8sMxE0N4"
   },
   "source": [
    "### Run the cells below to train the tabular and neural SARSA agents and to generate plots.\n",
    "\n",
    "This trains the agents the Grid problem with an epsilon of 0.1.\n",
    "\n",
    "The plots below will show action values for each of the actions, as well as a state value defined by $v(s) = \\sum_a \\pi(a|s) q(s, a)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4760,
     "status": "ok",
     "timestamp": 1523972092385,
     "user": {
      "displayName": "Yucheng Ji",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102198880449804016310"
     },
     "user_tz": -480
    },
    "id": "GsNBHNZtHCPe",
    "outputId": "e6ead08b-4bf6-4f9b-e60a-c6db29933a66"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAHBCAYAAAD+eWvWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCSwNI5cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29025811d0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = Grid()\n",
    "agent = Sarsa(number_of_states=grid._layout.size,\n",
    "              number_of_actions=4,\n",
    "              initial_state = grid.get_obs())\n",
    "run_experiment(grid, agent, int(1e5))\n",
    "q = agent.q_values.reshape(grid._layout.shape + (4,))\n",
    "plot_action_values(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11849,
     "status": "ok",
     "timestamp": 1524131111615,
     "user": {
      "displayName": "Yucheng Ji",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102198880449804016310"
     },
     "user_tz": -60
    },
    "id": "K-JnvcP0mrxF",
    "outputId": "e85bf954-20c0-42b8-ac38-6b4356dfce02"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAHBCAYAAAD+eWvWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAvEYAAAC8RgAAAL/0/e/w6Tb/9o5UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f44cacf3350>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vision_size = 1\n",
    "grid = Grid(tabular=False, vision_size=vision_size)\n",
    "agent = NeuralSarsa(number_of_features=(2*vision_size + 1)**2,\n",
    "                    number_of_hidden=100,\n",
    "                    number_of_actions=4,\n",
    "                    initial_state=grid.get_obs(),\n",
    "                    step_size=0.01)\n",
    "run_experiment(grid, agent, int(1e5))\n",
    "h, w = grid._layout.shape\n",
    "obs = np.array([[grid.get_obs_at(x, y) for x in range(2, w-2)] for y in range(2, h-2)])\n",
    "qs = np.array([[[agent.q(o)[a] for a in range(4)] if o[vision_size,vision_size] == 0 else np.zeros((4,)) for o in ob] for ob in obs])\n",
    "plot_action_values(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13046,
     "status": "ok",
     "timestamp": 1523972124684,
     "user": {
      "displayName": "Yucheng Ji",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102198880449804016310"
     },
     "user_tz": -480
    },
    "id": "tmGFDriIPsGz",
    "outputId": "77e4d866-dd2c-473b-bcaf-e199ca2512fc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAHBCAYAAAD+eWvWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2902513e10>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vision_size = 2\n",
    "grid = Grid(tabular=False, vision_size=vision_size)\n",
    "agent = NeuralSarsa(number_of_features=(2*vision_size + 1)**2,\n",
    "                    number_of_hidden=100,\n",
    "                    number_of_actions=4,\n",
    "                    initial_state=grid.get_obs(),\n",
    "                    step_size=0.01)\n",
    "run_experiment(grid, agent, int(1e5))\n",
    "h, w = grid._layout.shape\n",
    "obs = np.array([[grid.get_obs_at(x, y) for x in range(2, w-2)] for y in range(2, h-2)])\n",
    "qs = np.array([[[agent.q(o)[a] for a in range(4)] if o[vision_size,vision_size] == 0 else np.zeros((4,)) for o in ob] for ob in obs])\n",
    "plot_action_values(qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LGptHwE23lmP"
   },
   "source": [
    "## Questions\n",
    "\n",
    "Consider the greedy policy with respect to the estimated values\n",
    "\n",
    "**[5 pts]** Which algorithm performed best?  Why?\n",
    "\n",
    "Tabular Sarsa performs the best as it could find the optimal solution which will reach the goal at bottom right based on the value plot. However, neural sarsa cannot distinguish among the paths approach to goal point and two distractor points according to the action value plot. It could be attributed to that the feature vector of most states along the three corridors of the grid will be nearly the same on basis of the way to get feature vector through clipping (0,1).\n",
    "\n",
    "**[5 pts]** Is there a difference in the solution found by Neural Sarsa with a vision size of 1 (so 3x3 local observations), and a vision size of 2 (so 5x5 local observations)?  Why?\n",
    "\n",
    "There is no difference in the solution found by Neural Sarsa with a vision size of 1 and 2. For the reason, it can be refered back to the implementation of the environment. For both vision size, the feature representation of most states along the three corridors to the goal or distractor \"goal\" are the same through clipping (min=0, max=1). Neural sarsa cannot identified the real position in the grid due to the same feature representation. Only the states near the actual goal or distractors have different feature vector. Therefor, our neural sarsa cannot distinguish between the path to the actual goal and the paths to distractors. And that's why there is no difference in the solutions the algorithm found. (In addition, the value estimates only differ slightly for the horizontal and vertical path according to the plot.)\n",
    "\n",
    "**[10 pts]** How could we improve the performance of the Neural Sarsa agent on this domain (for both vision sizes)?  Identify the main issue, and propose a concrete solution (in max 200 words).\n",
    "\n",
    "The main issue is how to make more updates for the states near the actual goal point. And further learn the difference between the path to Goal and the paths to two distractor points. Instead of update the paramter one by one accroding to the current transition, we could try to use recurrent neural network (LSTM/GRU) as the network in Neural Sarsa. By using RNN, we are building a memory of the history traisions of states, and the action value will be learned not only based on the current feature representation of the state but also the previous history. As a result, the states on three verticle paths will be distinguished with consideration of the previous states in the transition path. And thus the performance of Neural Sarsa is improved. \n",
    "\n",
    "Other solution could be using n step temperal difference instead of TD(0). Through this change, the action value to move in the right direction can be increased, and the policy will encourage the agent to move to the actual goal. \n",
    "\n",
    "**[10 BONUS pts]** Implement your proposed improvement and show that it actually helps performance."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "17127155_RL_hw4.ipynb",
   "provenance": [
    {
     "file_id": "1a1ONHRz5bcd2rJyLUD53OUMR8npSp0QZ",
     "timestamp": 1522325021849
    },
    {
     "file_id": "1Ldj742iIDtvjYKKwENvrpTQ3Hm2wrqIg",
     "timestamp": 1521476023411
    },
    {
     "file_id": "1FwMxkDPkt68fxovrMmmWwm6ohYvX2wt1",
     "timestamp": 1517660129183
    },
    {
     "file_id": "1wwTq5nociiMHUb26jxrvZvGN6l11xV5o",
     "timestamp": 1517174839485
    },
    {
     "file_id": "1_gJNoj9wG4mnigscGRAcZx7RHix3HCjG",
     "timestamp": 1515086437469
    },
    {
     "file_id": "1hcBeMVfaSh8g1R2ujtmxOSHoxJ8xYkaW",
     "timestamp": 1511098107887
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
